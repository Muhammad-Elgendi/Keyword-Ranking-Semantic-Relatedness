{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keyword Ranking & Semantic Relatedness.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gqz80N7l_Oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BrambleXu's implementation of textrank\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "class TextRank4Keyword():\n",
        "    \"\"\"Extract keywords from text\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.d = 0.85 # damping coefficient, usually is .85\n",
        "        self.min_diff = 1e-5 # convergence threshold\n",
        "        self.steps = 100 # iteration steps\n",
        "        self.node_weight = None # save keywords and its weight\n",
        "        \n",
        "        # list of keywords which will hold a lists of keywords and their pr\n",
        "        self.keywords = []\n",
        "\n",
        "\n",
        "    \n",
        "    def set_stopwords(self, stopwords):  \n",
        "        \"\"\"Set stop words\"\"\"\n",
        "        for word in STOP_WORDS.union(set(stopwords)):\n",
        "            lexeme = nlp.vocab[word]\n",
        "            lexeme.is_stop = True\n",
        "    \n",
        "    def sentence_segment(self, doc, candidate_pos, lower):\n",
        "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
        "        sentences = []\n",
        "        for sent in doc.sents:\n",
        "            selected_words = []\n",
        "            for token in sent:\n",
        "                # Store words only with cadidate POS tag\n",
        "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
        "                    if lower is True:\n",
        "                        selected_words.append(token.text.lower())\n",
        "                    else:\n",
        "                        selected_words.append(token.text)\n",
        "            sentences.append(selected_words)\n",
        "        return sentences\n",
        "        \n",
        "    def get_vocab(self, sentences):\n",
        "        \"\"\"Get all tokens\"\"\"\n",
        "        vocab = OrderedDict()\n",
        "        i = 0\n",
        "        for sentence in sentences:\n",
        "            for word in sentence:\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = i\n",
        "                    i += 1\n",
        "        return vocab\n",
        "    \n",
        "    def get_token_pairs(self, window_size, sentences):\n",
        "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
        "        token_pairs = list()\n",
        "        for sentence in sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                for j in range(i+1, i+window_size):\n",
        "                    if j >= len(sentence):\n",
        "                        break\n",
        "                    pair = (word, sentence[j])\n",
        "                    if pair not in token_pairs:\n",
        "                        token_pairs.append(pair)\n",
        "        return token_pairs\n",
        "        \n",
        "    def symmetrize(self, a):\n",
        "        return a + a.T - np.diag(a.diagonal())\n",
        "    \n",
        "    def get_matrix(self, vocab, token_pairs):\n",
        "        \"\"\"Get normalized matrix\"\"\"\n",
        "        # Build matrix\n",
        "        vocab_size = len(vocab)\n",
        "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
        "        for word1, word2 in token_pairs:\n",
        "            i, j = vocab[word1], vocab[word2]\n",
        "            g[i][j] = 1\n",
        "            \n",
        "        # Get Symmeric matrix\n",
        "        g = self.symmetrize(g)\n",
        "        \n",
        "        # Normalize matrix by column\n",
        "        norm = np.sum(g, axis=0)\n",
        "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
        "        \n",
        "        return g_norm\n",
        "\n",
        "    \n",
        "    def get_keywords(self, number=10):\n",
        "        \"\"\"Print top number keywords\"\"\"\n",
        "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
        "        for i, (key, value) in enumerate(node_weight.items()):\n",
        "            if(i < number):\n",
        "              # add keyword and its pr\n",
        "              self.keywords.append([key,value]) \n",
        "        return self.keywords\n",
        "           \n",
        "        \n",
        "        \n",
        "    def analyze(self, text, \n",
        "                candidate_pos=['NOUN', 'PROPN'], \n",
        "                window_size=4, lower=False, stopwords=list()):\n",
        "        \"\"\"Main function to analyze text\"\"\"\n",
        "        \n",
        "        # Set stop words\n",
        "        self.set_stopwords(stopwords)\n",
        "        \n",
        "        # Pare text by spaCy\n",
        "        doc = nlp(text)\n",
        "        \n",
        "        # Filter sentences\n",
        "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
        "        \n",
        "        # Build vocabulary\n",
        "        vocab = self.get_vocab(sentences)\n",
        "        \n",
        "        # Get token_pairs from windows\n",
        "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
        "        \n",
        "        # Get normalized matrix\n",
        "        g = self.get_matrix(vocab, token_pairs)\n",
        "        \n",
        "        # Initionlization for weight(pagerank value)\n",
        "        pr = np.array([1] * len(vocab))\n",
        "        \n",
        "        # Iteration\n",
        "        previous_pr = 0\n",
        "        for epoch in range(self.steps):\n",
        "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
        "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
        "                break\n",
        "            else:\n",
        "                previous_pr = sum(pr)\n",
        "\n",
        "        # Get weight for each node\n",
        "        node_weight = dict()\n",
        "        for word, index in vocab.items():\n",
        "            node_weight[word] = pr[index]\n",
        "        \n",
        "        self.node_weight = node_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiNltq_VmCww",
        "colab_type": "code",
        "outputId": "74683791-ef94-4f52-fa60-b06025ceb11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "text1 = '''An intelligent virtual assistant (IVA) or intelligent personal assistant (IPA) is a software agent that can perform tasks or services for an individual based on commands or questions. Sometimes the term \"chatbot\" is used to refer to virtual assistants generally or specifically accessed by online chat. In some cases, online chat programs are exclusively for entertainment purposes. Some virtual assistants are able to interpret human speech and respond via synthesized voices. Users can ask their assistants questions, control home automation devices and media playback via voice, and manage other basic tasks such as email, to-do lists, and calendars with verbal (spoken?) commands.[1] A similar concept, however with differences, lays under the dialogue systems.[2]\n",
        "\n",
        "As of 2017, the capabilities and usage of virtual assistants are expanding rapidly, with new products entering the market and a strong emphasis on both email and voice user interfaces. Apple and Google have large installed bases of users on smartphones. Microsoft has a large installed base of Windows-based personal computers, smartphones and smart speakers. Amazon has a large install base for smart speakers.[3] Conversica has over 100 million engagements via its email and sms interface Intelligent Virtual Assistants for business.'''\n",
        "text2 = '''Google Assistant is an artificial intelligenceâ€“powered[1] virtual assistant developed by Google that is primarily available on mobile and smart home devices. Unlike the company's previous virtual assistant, Google Now, the Google Assistant can engage in two-way conversations.\n",
        "\n",
        "Assistant initially debuted in May 2016 as part of Google's messaging app Allo, and its voice-activated speaker Google Home. After a period of exclusivity on the Pixel and Pixel XL smartphones, it began to be deployed on other Android devices in February 2017, including third-party smartphones and Android Wear (now Wear OS), and was released as a standalone app on the iOS operating system in May 2017. Alongside the announcement of a software development kit in April 2017, the Assistant has been further extended to support a large variety of devices, including cars and third party smart home appliances. The functionality of the Assistant can also be enhanced by third-party developers.\n",
        "\n",
        "Users primarily interact with the Google Assistant through natural voice, though keyboard input is also supported. In the same nature and manner as Google Now, the Assistant is able to search the Internet, schedule events and alarms, adjust hardware settings on the user's device, and show information from the user's Google account. Google has also announced that the Assistant will be able to identify objects and gather visual information through the device's camera, and support purchasing products and sending money, as well as identifying songs.\n",
        "\n",
        "At CES 2018, the first Assistant-powered smart displays (smart speakers with video screens) were announced, with the first one being released in July 2018.[2] In 2020, Google Assistant is already available on more than 1 billion devices.[3] Google Assistant is available in more than 90 countries and in over 30 languages,[4] and is used by more than 500 million users monthly.[5]'''\n",
        "\n",
        "# read text from pages\n",
        "virtualFile=open('virtual assistant.txt','r', encoding='utf-8')\n",
        "# converts to lowercase\n",
        "page1 = virtualFile.read().lower()\n",
        "\n",
        "googleFile=open('google assistant.txt','r', encoding='utf-8')\n",
        "# converts to lowercase\n",
        "page2 = googleFile.read().lower()\n",
        "\n",
        "# use files instead of strings above\n",
        "#text1 = page1\n",
        "#text2 = page2\n",
        "\n",
        "# number of extracted keywords per page\n",
        "keywordsCount = 100\n",
        "\n",
        "# extract only these POS\n",
        "extracted_pos = ['NOUN', 'PROPN','VERB']\n",
        "\n",
        "# using BrambleXu's implementation of textrank\n",
        "tr4w1 = TextRank4Keyword()\n",
        "tr4w1.analyze(text1, candidate_pos = extracted_pos, window_size=4, lower=False)\n",
        "keywords1 = tr4w1.get_keywords(keywordsCount)\n",
        "print(\"keywords of text1\\n\",keywords1)\n",
        "\n",
        "tr4w2 = TextRank4Keyword()\n",
        "tr4w2.analyze(text2, candidate_pos = extracted_pos, window_size=4, lower=False)\n",
        "keywords2 = tr4w2.get_keywords(keywordsCount)\n",
        "print(\"keywords of text2\\n\",keywords2)\n",
        "\n",
        "# combine keywords of each page\n",
        "sentence1 =\"\"\n",
        "for keyword in keywords1 :\n",
        "  sentence1 += keyword[0] + \" \" \n",
        "\n",
        "print(\"sentence1 : \\n\",sentence1)\n",
        "\n",
        "sentence2 =\"\"\n",
        "for keyword in keywords2 :\n",
        "  sentence2 += keyword[0] + \" \" \n",
        "\n",
        "print(\"sentence2 : \\n\",sentence2)\n",
        "\n",
        "# lemmatization\n",
        "import nltk\n",
        "\n",
        "# first-time use only\n",
        "nltk.download('wordnet') # limmtization\n",
        "nltk.download('punkt') # tokenization\n",
        "\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# build a customized tokenizer  \n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens([token for token in nltk.word_tokenize(text.lower())])\n",
        "\n",
        "# Apply TF-IDF vectorization to lemmatized text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "TfidfVec = TfidfVectorizer(tokenizer=LemNormalize)\n",
        "tfidf = TfidfVec.fit_transform([sentence1,sentence2])\n",
        "\n",
        "# apply cosine similarity between two pages\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "metrix = cosine_similarity(tfidf[0], tfidf[1])\n",
        "\n",
        "print(\"Semantic relatedness between the two pages is \",metrix[0][0]*100 ,\"%\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keywords of text1\n",
            " [['assistants', 2.9623285243306072], ['email', 2.6014164562289563], ['tasks', 1.8026550174362672], ['based', 1.7905509870530705], ['voice', 1.6160261994949492], ['chat', 1.4798499228395063], ['base', 1.474827417027417], ['questions', 1.4043983686067016], ['smartphones', 1.328450333694084], ['interface', 1.1842828282828282], ['sms', 1.1502828282828284], ['installed', 1.0994527597402597], ['bases', 1.0994527597402597], ['differences', 1.0814583333333332], ['lays', 1.0814583333333332], ['dialogue', 1.0814583333333332], ['assistant', 1.071659722222222], ['speech', 1.065813910934744], ['respond', 1.065813910934744], ['Intelligent', 1.0277411616161616], ['software', 1.025762941919192], ['entering', 1.0136300304633639], ['agent', 1.010029356060606], ['expanding', 1.0068562510020844], ['control', 1.0028733666025333], ['refer', 1.0025822310405643], ['products', 1.0002916466249798], ['home', 0.9931606140772806], ['Windows', 0.9823370490620491], ['computers', 0.9823370490620491], ['market', 0.9730385101010101], ['perform', 0.970133733164983], ['individual', 0.96705849667308], ['manage', 0.9633525883838384], ['programs', 0.9587058531746031], ['entertainment', 0.9587058531746031], ['emphasis', 0.9538455387205387], ['services', 0.9496733255170755], ['automation', 0.937168209876543], ['devices', 0.9220475589225589], ['users', 0.9207857954545454], ['Google', 0.9150455357142856], ['playback', 0.9148408038720537], ['media', 0.9039528619528617], ['IPA', 0.8910347222222221], ['interpret', 0.8903007164902996], ['concept', 0.8778125], ['systems.[2', 0.8778125], ['synthesized', 0.8740465277777776], ['accessed', 0.8639203593474426], ['lists', 0.8575587121212122], ['Assistants', 0.8531388888888888], ['Amazon', 0.8314227994227994], ['install', 0.8314227994227994], ['speakers.[3', 0.8314227994227994], ['engagements', 0.8053244949494948], ['chatbot', 0.8029587191358024], ['cases', 0.7873144841269841], ['purposes', 0.7873144841269841], ['IVA', 0.7851388888888889], ['usage', 0.7680620590828925], ['Apple', 0.750408630952381], ['calendars', 0.7445527146464647], ['ask', 0.7359426006092672], ['voices', 0.7251784722222222], ['commands', 0.7062433662016995], ['user', 0.6997935606060606], ['business', 0.6777083333333332], ['term', 0.6731088514109347], ['Microsoft', 0.6649945165945166], ['Conversica', 0.6383939393939393], ['capabilities', 0.6358398368606701], ['speakers', 0.6288695165945166], ['Users', 0.6137551006092672], ['spoken', 0.6109460227272727], ['interfaces', 0.5806647727272727], ['commands.[1', 0.15000000000000002]]\n",
            "keywords of text2\n",
            " [['Assistant', 5.5204753194880505], ['Google', 4.599664992071344], ['voice', 1.751114514142171], ['party', 1.7208972806323168], ['devices', 1.5989950308909928], ['support', 1.5847459658970657], ['app', 1.5430201041005183], ['device', 1.4992381827170203], ['information', 1.4137164455575841], ['released', 1.3698764161629375], ['announced', 1.3227320742884872], ['smartphones', 1.2932839099364895], ['user', 1.2766272703299602], ['Android', 1.2688218533667657], ['including', 1.2561538815504107], ['Pixel', 1.2443646214896216], ['assistant', 1.125489591126632], ['home', 1.088156735346216], ['sending', 1.08571910405486], ['kit', 1.0717056283934343], ['Wear', 1.0347626937217425], ['products', 1.0263371596104154], ['April', 1.013751121337183], ['speakers', 0.9981273196822972], ['video', 0.9968149969316841], ['displays', 0.9870510658478835], ['screens', 0.96763971700059], ['money', 0.9664722222222222], ['development', 0.9653462316532236], ['Internet', 0.9627919961352308], ['began', 0.9590860349221179], ['XL', 0.9581737382987383], ['purchasing', 0.9575014505460879], ['countries', 0.9509596504939959], ['languages,[4', 0.9509596504939959], ['search', 0.942231978115375], ['schedule', 0.9409895065070248], ['activated', 0.9341992040843603], ['Allo', 0.9154999239513287], ['adjust', 0.9010725367197062], ['events', 0.8983361043111654], ['messaging', 0.8957203017477469], ['alarms', 0.8943738015095879], ['extended', 0.8874784218412644], ['hardware', 0.8862211622807017], ['keyboard', 0.8809633976503822], ['identify', 0.8697653823759186], ['settings', 0.8641354532163743], ['deployed', 0.8571950092810923], ['developed', 0.8464082000761614], ['powered', 0.837898395735911], ['camera', 0.8376327957453262], ['identifying', 0.834486111111111], ['variety', 0.8331770056218247], ['February', 0.8309843801587569], ['cars', 0.8256828900311632], ['objects', 0.8238702392389406], ['OS', 0.8205619899639949], ['gather', 0.8080195990996175], ['speaker', 0.790027710008261], ['users', 0.7897397054054337], ['software', 0.7892598514211886], ['intelligence', 0.7811909339197359], ['exclusivity', 0.7555462962962963], ['engage', 0.7522402017995855], ['way', 0.7522402017995855], ['input', 0.7239580358951534], ['operating', 0.7217128203505396], ['enhanced', 0.688207406926966], ['songs', 0.6862083333333333], ['interact', 0.6772047829692996], ['debuted', 0.6720899367452123], ['manner', 0.6697078808081532], ['announcement', 0.6582511304909561], ['monthly.[5', 0.6102434414524684], ['system', 0.6091397443524635], ['functionality', 0.6049243866526668], ['developers', 0.6049243866526668], ['period', 0.6004212962962963], ['CES', 0.5967465869503813], ['conversations', 0.5913754204197136], ['July', 0.5773352381030878], ['nature', 0.568670676605787], ['Home', 0.555910643535702], ['Users', 0.5536185932724537], ['supported', 0.5514860774977437], ['appliances', 0.5253641415048201], ['account', 0.5042550115580304], ['devices.[3', 0.43752930573675397], ['company', 0.40299206042413954]]\n",
            "sentence1 : \n",
            " assistants email tasks based voice chat base questions smartphones interface sms installed bases differences lays dialogue assistant speech respond Intelligent software entering agent expanding control refer products home Windows computers market perform individual manage programs entertainment emphasis services automation devices users Google playback media IPA interpret concept systems.[2 synthesized accessed lists Assistants Amazon install speakers.[3 engagements chatbot cases purposes IVA usage Apple calendars ask voices commands user business term Microsoft Conversica capabilities speakers Users spoken interfaces commands.[1 \n",
            "sentence2 : \n",
            " Assistant Google voice party devices support app device information released announced smartphones user Android including Pixel assistant home sending kit Wear products April speakers video displays screens money development Internet began XL purchasing countries languages,[4 search schedule activated Allo adjust events messaging alarms extended hardware keyboard identify settings deployed developed powered camera identifying variety February cars objects OS gather speaker users software intelligence exclusivity engage way input operating enhanced songs interact debuted manner announcement monthly.[5 system functionality developers period CES conversations July nature Home Users supported appliances account devices.[3 company \n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Semantic relatedness between the two pages is  24.460659478420776 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}